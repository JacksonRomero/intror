Inferencia estadística
======================


```{r , child = '_global_options.Rmd'}
```

El objetivo de este capítulo es ofrecer un primer acercamiento a la inferencia estadística,
cubriendo de forma somera los siguientes apartados:

* contrastes de normalidad
* contrastes paramétricos y no paramétricos, con una y dos muestras
* regresión y correlación
* análisis de la varianza con un factor

### Datos de ejemplo
El fichero *hatco.RData* contiene datos de clientes de una compañía de distribución industrial
que utilizaremos a modo de ejemplo.

```{r }
load('datos/hatco.RData')
```

Listado de etiquetas

```{r }
as.data.frame(attr(hatco, "variable.labels"))
```

Para poder, de ahora en adelante, referenciar directamente las variables de *hatco*

```{r }
# attach(hatco)
satisfac <- hatco$satisfac
```


Normalidad
----------
Queremos hacer un estudio inferencial de la variable *satisfac* (satisfacción global). Lo primero
que vamos a hacer es comprobar si, visualmente, los datos parecen razonablemente
simétricos y si se pueden ajustar por una distribución normal

```{r }
hist(satisfac)
qqnorm(satisfac)
shapiro.test(satisfac)
```


Contrastes
----------

### Una muestra
Obtenemos un intervalo de confianza de *satisfac*

```{r }
t.test(satisfac)
```

Contrastamos si es razonable suponer que la media es 5

```{r }
t.test(satisfac, mu=5)
```

Utilizando una confianza del 99%

```{r }
t.test(satisfac, mu=5, conf.level=0.99)
```

Veamos si podemos afirmar que la media es menor que 5

```{r }
t.test(satisfac, mu=5, alternative = 'less')
```

¿Y mayor que 4.65?

```{r }
t.test(satisfac, mu=4.65, alternative = 'greater')
```

El test de los rangos con signo de Wilcoxon es un contraste no paramétrico
(exige que la distribución sea simétrica) que se puede utilizar como
alternativa al contraste *t* de Student

```{r }
wilcox.test(satisfac, mu=5)
```


### Dos muestras
Disponemos de dos muestras independientes, el porcentaje de compra
en las empresas con nivel de satisfacción bajo y alto,
y asumimos que las varianzas son iguales

```{r }
t.test(fidelida ~ nsatisfa, data = hatco, var.equal=TRUE)
```

Si no se asume igualdad de varianzas, se calcula la variante Welch del test *t*

```{r }
t.test(fidelida ~ nsatisfa, data = hatco)
```

Comparemos visualmente las varianzas

```{r }
boxplot(fidelida ~ nsatisfa, data = hatco)
```

La comparación de las varianzas puede hacerse con el test *F*

```{r }
var.test(fidelida ~ nsatisfa, data = hatco)
```

Una alternativa no paramétrica

```{r }
bartlett.test(fidelida ~ nsatisfa, data = hatco)
```

También puede utilizarse el test de Wilcoxon como alternativa al test *t*

```{r }
wilcox.test(fidelida ~ nsatisfa, data = hatco)
```

Si disponemos de datos apareados, por ejemplo nivel de precios e imagen
de fuerza de ventas

```{r }
# t.test(precio, imgfvent, paired=T)
# PROBLEMA ATTACH
```

Y la correspondiente alternativa no paramétrica

```{r }
# wilcox.test(precio, imgfvent, paired=T)
# PROBLEMA ATTACH

```


Regresión y correlación
-----------------------

### Regresión lineal simple
Utilizando la función *lm* (modelo lineal) se puede llevar a cabo, entre otras
muchas cosas, una regresión lineal simple

```{r }
lm(satisfac~fidelida, data = hatco)

modelo <- lm(satisfac~fidelida, data = hatco, na.action=na.exclude)
summary(modelo)

plot(hatco$fidelida, hatco$satisfac)  # Cuidado con el orden de las variables
plot(satisfac~fidelida, data = hatco)  # Alternativa empleando fórmulas
abline(modelo)
```

Valores ajustados

```{r }
fitted(modelo)
```

Residuos

```{r }
head(resid(modelo))
qqnorm(resid(modelo))
shapiro.test(resid(modelo))

plot(fidelida, satisfac)
abline(modelo)
segments(fidelida, fitted(modelo), fidelida, satisfac)

plot(fitted(modelo), resid(modelo))
```

Banda de confianza

```{r }
predict(modelo, interval='confidence')
```

Banda de predicción

```{r }
head(predict(modelo, interval='prediction'))
```

Representación gráfica de las bandas

```{r }
bandas.frame <- data.frame(fidelida=24:66)
bc <- predict(modelo, interval = 'confidence', newdata = bandas.frame)
bp <- predict(modelo, interval = 'prediction', newdata = bandas.frame)
plot(fidelida, satisfac, ylim=range(satisfac,bp,na.rm=T))
matlines(bandas.frame$fidelida, bc, lty=c(1,2,2), col='black')
matlines(bandas.frame$fidelida, bp, lty=c(0,3,3), col='red')
```


### Correlación
Coeficiente de correlación de Pearson

```{r }
cor(fidelida, satisfac, use='complete.obs')
cor(hatco[,6:14], use='complete.obs')
cor.test(fidelida, satisfac)
```

El coeficiente de correlación de Spearman es una variante no paramétrica

```{r }
cor.test(fidelida, satisfac, method='spearman')
```


Análisis de la varianza
-----------------------

### ANOVA con un factor
Vamos a estudiar si hay diferencias en las medias de la variable *satisfac*
(satisfacción global) entre los diferentes grupos definidos por *nfidelid*
(nivel de compra), utilizando el procedimiento clásico de análisis de la
varianza. Este procedimiento exige normalidad y homocedasticidad.

```{r }
table(nfidelid)
tapply(satisfac, nfidelid, mean, na.rm=T)
```

La variable explicativa tiene que ser obligatoriamente de tipo *factor*.
Por coherencia con la función (general) *lm*, la variación entre grupos
está etiquetada *nfidelid*, y la variación dentro de los grupos como
*Residuals*

```{r }
anova(lm(satisfac~nfidelid))
```

Como alternativa, se puede utilizar la función *aov*

```{r }
aov(satisfac~nfidelid)
summary(aov(satisfac~nfidelid))
```

Comparaciones entre pares de variables

```{r }
pairwise.t.test(satisfac,nfidelid)
```

Relajamos la hipótesis de varianzas iguales

```{r }
oneway.test(satisfac~nfidelid)
```

Podemos utilizar el test de Bartlett para contrastar la igualdad de varianzas

```{r }
bartlett.test(satisfac~nfidelid)
```

Representación gráfica

```{r }
medias <- tapply(satisfac, nfidelid, mean, na.rm=T)
desviaciones <- tapply(satisfac, nfidelid, sd, na.rm=T)
n <- tapply(satisfac[!is.na(satisfac)], nfidelid[!is.na(satisfac)], length)
errores <- desviaciones/sqrt(n)
stripchart(satisfac~nfidelid, method='jitter', jit=0.01, pch=18, col='grey', vertical=T)
arrows(1:3, medias+errores, 1:3, medias-errores, angle=90, code=3, lwd=2, col='orange')
points(1:3, medias, pch=4, lwd=2, cex=2, col='orange')
```


### Test de Kruskal-Wallis
Alternativa no paramétrica al análisis de la varianza con un factor

```{r }
kruskal.test(satisfac~nfidelid)
```

